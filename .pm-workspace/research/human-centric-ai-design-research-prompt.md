# Deep Research Prompt: Human-Centric Design for AI Products

> **Purpose**: Establish foundational knowledge for a Design Companion Agent that ensures user experience, emotional design, and aesthetic excellence are embedded in every PRD, prototype, and product decision for AskElephant.

---

## Research Context

**Product**: AskElephant — A revenue outcome system that converts conversation + operational context into reliable actions, risk detection, and execution, while keeping humans at the center.

**Core Philosophy**: 
> "It's not what you build...It's how it's delivered, how it's used, and how it is experienced." — Woody Klemetson, CEO

**Design Challenge**: Build AI interfaces that feel like trusted partners, not black boxes. Create experiences where automation enhances human agency rather than replacing it. Make complex AI workflows feel simple, trustworthy, and even delightful.

**Target Personas**: Sales Reps, Sales Leaders, Customer Success Managers, RevOps — busy professionals who need AI to work *with* them, not require them to learn a new system.

---

## Research Objectives

### 1. Foundational Frameworks for Human-Centric AI Design

Search for and synthesize knowledge on:

- **The AI-Human Interaction Paradigm**: What makes AI interfaces fundamentally different from traditional software? How do users form mental models of AI behavior?
- **Trust Formation in AI Systems**: What visual, behavioral, and feedback patterns build trust? What destroys it?
- **The "Appropriate Anthropomorphism" Spectrum**: When should AI feel human? When should it feel explicitly machine-like?
- **Explainability vs. Simplicity Tradeoffs**: How do we make AI decisions transparent without overwhelming users?

**Key Questions to Answer**:
- What are the leading academic and industry frameworks for AI UX design (e.g., Google's People + AI Guidebook, Microsoft's HAX Toolkit)?
- What cognitive science principles govern human trust in automated systems?
- How do concepts like "calibrated trust" apply to AI product design?

---

### 2. Visual Design Language for AI Experiences

Search for patterns, anti-patterns, and emerging aesthetics in:

- **Conversational UI Design**: Beyond chatbots—how do you design conversation interfaces that feel intelligent, not clunky?
- **AI Status & State Communication**: Progress indicators, confidence levels, "thinking" states—what visual metaphors work best?
- **Error States & Uncertainty**: How do world-class AI products communicate mistakes, low confidence, or "I don't know"?
- **Typography for Trust**: Font choices that convey reliability, approachability, and intelligence
- **Color Psychology in AI Contexts**: What palettes signal trustworthiness vs. innovation vs. warmth?
- **Animation & Motion in AI Interfaces**: How do micro-animations build confidence in AI processing?

**Key Questions to Answer**:
- What are the most beautiful, functional AI product interfaces in 2024-2026? (Notion AI, Linear, Loom AI, Grammarly, etc.)
- What design systems are AI-native companies building?
- How do you avoid the "AI slop" aesthetic while maintaining consistency?

---

### 3. Emotional Design & User Confidence

Search for research and examples on:

- **Emotional Responses to AI**: How do users feel when AI performs perfectly? When it fails? How do we design for both?
- **Perceived Control vs. Automation**: How do you give users the feeling of control even when AI is doing the work?
- **Delight in AI Products**: What makes an AI interaction feel magical rather than transactional?
- **Reducing AI Anxiety**: How do we address user fears about being replaced, surveilled, or misunderstood?

**Key Questions to Answer**:
- What emotional design frameworks (e.g., Don Norman's "Emotional Design") apply to AI products?
- How do you design "success moments" for AI that feel earned rather than random?
- What makes users feel like collaborators with AI rather than subjects of AI?

---

### 4. Accessibility in AI-First Interfaces

Search for guidelines and innovations on:

- **Screen Reader Compatibility for Dynamic AI Content**: How do you make AI-generated content accessible?
- **Cognitive Accessibility**: AI can overwhelm—how do you design for users with attention, memory, or processing differences?
- **Multimodal AI Interactions**: Voice, text, visual—how do accessible AI products offer multiple input/output modes?
- **Reading Level & Language Clarity**: AI-generated content must be universally understandable

**Key Questions to Answer**:
- What WCAG extensions or AI-specific accessibility guidelines exist?
- How do leading AI products handle accessibility audits?
- What's the intersection of plain language and AI explanations?

---

### 5. The AI-First UX Paradigm

AskElephant's leadership has articulated:
> "Your settings are not toggles anymore...It's a chat...AI first."

Search for research and examples on:

- **Conversational Configuration**: How do users configure AI through natural language instead of forms?
- **Proactive AI**: When should AI interrupt, suggest, or act autonomously? When should it wait?
- **AI as Copilot vs. Autopilot**: Design patterns for different levels of AI autonomy
- **The Disappearing UI**: Interfaces that fade away as AI takes over, without losing user control
- **Context-Aware Personalization**: How do you make AI feel like it knows the user without being creepy?

**Key Questions to Answer**:
- What are the design patterns for "invisible AI"—AI that's so integrated it doesn't feel like a separate feature?
- How do GitHub Copilot, Notion AI, and Linear approach AI integration aesthetically?
- What's the UX of "teaching" an AI your preferences?

---

### 6. Trust, Privacy, and Transparency Design

AskElephant has a specific trust challenge:
> "Trust and reliability must be solved *before* automation can be adopted at scale."

Search for research on:

- **Privacy-by-Design Visualization**: How do you communicate what data AI is accessing and why?
- **Data Transparency Patterns**: What UI patterns show users what the AI "knows" about them?
- **Consent Flows for AI Features**: How do you make opt-in/opt-out feel empowering rather than paranoid?
- **Audit Trails for AI Decisions**: How do users verify what the AI did and why?
- **Recovery from AI Mistakes**: Design patterns for graceful failure and easy correction

**Key Questions to Answer**:
- What are the visual design patterns for AI transparency (e.g., Anthropic's Constitutional AI explanations)?
- How do you show users the "receipts" for AI actions in CRM/workflow contexts?
- What makes a privacy dashboard feel reassuring rather than alarming?

---

### 7. B2B Enterprise AI UX Considerations

AskElephant serves mid-market B2B sales teams:

Search for insights on:

- **Enterprise AI Adoption Friction**: What design patterns reduce fear of AI in corporate environments?
- **Role-Based AI Experiences**: How do you design AI for reps vs. managers vs. admins?
- **Team Collaboration with AI**: How do multiple users share, review, and refine AI outputs?
- **Workflow Integration Aesthetics**: How do you make AI feel native to Salesforce, HubSpot, Slack environments?
- **Data Density in AI Dashboards**: How do you display rich AI insights without cognitive overload?

**Key Questions to Answer**:
- What are the best B2B AI product interfaces (Gong, Clari, Outreach, Chorus)?
- How do you design AI coaching tools that leaders actually use?
- What's the balance between "AI as magic" and "AI as reliable tool" in enterprise contexts?

---

### 8. Design Resources & Thought Leadership

Compile a reference library of:

**Frameworks & Guidelines**:
- Google People + AI Research (PAIR) Guidebook
- Microsoft Human-AI Interaction (HAX) Toolkit
- Apple Human Interface Guidelines for AI/ML
- IBM Design for AI
- Anthropic's Constitutional AI approach

**Books & Foundational Texts**:
- "Emotional Design" — Don Norman
- "Designing AI Products" — Fabrice Bricel
- "Human + Machine" — Paul Daugherty & H. James Wilson
- "Artificial Unintelligence" — Meredith Broussard (critical perspective)
- "The UX of AI" — Josh Clark

**Thought Leaders to Follow**:
- Jared Spool (AI UX)
- Cassie Kozyrkov (Decision Intelligence)
- Cliff Kuang (Co-author, "User Friendly")
- Aza Raskin (Humane Technology)
- Reid Hoffman (AI entrepreneurship)

**Design Inspiration Sources**:
- Mobbin (AI filter)
- Refero.design
- Bestwebsite.gallery (AI section)
- Dribbble/Behance AI product showcases
- Linear's changelog (design-forward product)

**Research Papers & Reports**:
- Nielsen Norman Group AI UX reports
- Forrester AI Design research
- Stanford HAI publications
- MIT Technology Review design coverage

---

## Integration with AskElephant PM Process

### How This Research Informs Every PM Artifact

**PRDs Must Include**:
- User emotional journey (not just functional journey)
- Trust implications assessment
- Visual/aesthetic requirements (not just "make it look good")
- Accessibility checklist
- AI transparency requirements

**Design Briefs Must Include**:
- Emotional design goals for each state (success, failure, loading, empty)
- Micro-interaction specifications
- Trust-building visual elements
- Accessibility specifications
- Competitive aesthetic analysis

**Prototypes Must Demonstrate**:
- Visual polish that matches research insights
- AI state handling (loading, confidence, error)
- Accessibility compliance
- Emotional resonance testing criteria
- Trust-building UI patterns

**Engineering Specs Must Consider**:
- Frontend performance for AI responsiveness
- Animation/transition implementation notes
- Accessibility implementation requirements
- Telemetry for UX research

---

## Design Companion Agent Role

Once this research is synthesized, the Design Companion Agent should:

1. **Review every PRD** for emotional design, trust implications, and accessibility gaps
2. **Critique prototypes** against human-centric AI design principles
3. **Suggest visual patterns** from best-in-class AI products
4. **Flag potential trust erosion** in proposed features
5. **Recommend A/B test hypotheses** for emotional/aesthetic elements
6. **Maintain a living design system** based on these principles
7. **Advocate for user feeling** alongside user function

### Agent Personality & Voice

The Design Companion should embody:
- **Empathy First**: Always starts with "How will the user feel?"
- **Beauty as Function**: Rejects the dichotomy of pretty vs. useful
- **Trust as Metric**: Treats trust erosion as seriously as bugs
- **Accessibility as Default**: Not an afterthought
- **Research-Grounded**: Cites frameworks and research, not just opinions

---

## Research Execution Plan

### Phase 1: Foundational Literature (2-3 hours)
- Read Google PAIR Guidebook
- Read Microsoft HAX Toolkit
- Review Apple HIG for AI/ML
- Compile core principles document

### Phase 2: Competitive Analysis (2-3 hours)
- Audit top 10 B2B AI product interfaces
- Screenshot and annotate design patterns
- Identify patterns applicable to AskElephant

### Phase 3: Trust & Privacy Deep Dive (2 hours)
- Research trust calibration frameworks
- Analyze privacy transparency patterns
- Document applicable patterns

### Phase 4: Emotional Design Synthesis (2 hours)
- Map emotional journeys for key AskElephant flows
- Identify delight opportunities
- Document anxiety-reduction patterns

### Phase 5: Accessibility Audit (1-2 hours)
- Review WCAG AI extensions
- Audit current AskElephant accessibility
- Create improvement roadmap

### Phase 6: Design Principles Codification (2 hours)
- Synthesize research into actionable principles
- Create "AskElephant Design Companion" reference doc
- Integrate into PRD/Design Brief templates

---

## Success Metrics for Design Excellence

After implementing Design Companion Agent:

**Qualitative**:
- User interviews mention "trust," "confidence," "ease" more frequently
- Reduced support tickets about confusion or uncertainty
- Increased feature adoption without training

**Quantitative**:
- NPS improvement (emotional resonance)
- Task completion rate improvement
- Time-to-value reduction
- Accessibility audit scores

---

## Appendix: Key Quotes to Ground Research

From AskElephant Leadership:

> "Taking unstructured data from one place and giving it to the right person at the right time and the right format."

> "If you are not helping orchestrate a human outcome, then you are not working on the right thing."

> "I wanna build an AI that leaves no human behind..."

> "Technology is not a moat...It matters about the outcome that what they build delivers."

> "Your settings are not toggles anymore...It's a chat...AI first."

These quotes should inform every design decision. The Design Companion Agent exists to ensure we never build features that violate these principles.

---

*This research prompt should be used with web search, academic databases, and competitive analysis tools to build the knowledge base for the AskElephant Design Companion Agent.*

